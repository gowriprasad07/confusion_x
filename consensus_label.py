# -*- coding: utf-8 -*-
"""Consensus_Label

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zZPuUt5Rf5tjKCwV1bQa0Mnn_fSGx_pb
"""

#Labelling Dataset - Using Consensus between VADER, SentiStrength, TextBlob

from google.colab import drive
drive.mount('/content/gdrive')

from pickle import load,dump

f1=open("/content/gdrive/My Drive/Colab Notebooks/Updated_Dataset_CSA/Dataset_Raw_2.pickle","rb")
data=load(f1)

data[1]

###
#VADER
###

!pip install vaderSentiment

from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
vader=SentimentIntensityAnalyzer()

final_list={}

for i in data:
  temp={}
  
  for j in i:
    temp[j]=i[j]
  
  lb=vader.polarity_scores(i["tweet_text"])

  if lb["compound"]>=0.05:
    temp["label"]=[1]

  elif lb["compound"]<=0.05:
    temp["label"]=[-1]
  
  else:
    temp["label"]=[0]
  
  final_list[i["tweet_id"]]=temp

final_list[243566853119676416]

###
#SentiStrength
###

f2=open("/content/gdrive/My Drive/Colab Notebooks/Updated_Dataset_CSA/Dataset_V2_CSA+results.txt","r")

while 1:
  try:
    a=f2.readline()
    if a=='':
      break
    a=a.split("\t")
    sc=int(a[-2])+int(a[-3])

    if sc>0:
      final_list[int(a[0])]["label"].append(1)
    elif sc<0:
      final_list[int(a[0])]["label"].append(-1)
    else:
      final_list[int(a[0])]["label"].append(0)

    if int(a[0])==243566853119676416:
      print("Here ",sc)

  except EOFError:
    break

final_list[243566853119676416]

a.split("\t")

###
#TextBlob
###

!pip install -U textblob
!python -m textblob.download_corpora

from textblob import TextBlob

for i in final_list:
  a=TextBlob(final_list[i]["tweet_text"])

  if a.sentiment.polarity>0:
    final_list[i]["label"].append(1)
  elif a.sentiment.polarity<0:
    final_list[i]["label"].append(-1)
  else:
    final_list[i]["label"].append(0)

  if i==243566853119676416:
    print(a.sentiment.polarity)

final_list[243566853119676416]

wrong_count=0

for i in final_list:
  final_list[i]['label'].sort()
  if final_list[i]['label']==[-1,0,1]:
    wrong_count+=1

wrong_count

wrong_count

def most_freq(List):
  return max(set(List), key = List.count)

wrong_count=0
final_list_2={}
from copy import deepcopy

for i in final_list:
  final_list[i]['label'].sort()
  if final_list[i]['label']==[-1,0,1]:
    wrong_count+=1
    continue
  else:
    final_list_2[i]=deepcopy(final_list[i])
    final_list_2[i]["label"]=most_freq(final_list[i]["label"])

len(final_list_2)

100996-14718

final_list_2[243566853119676416]

nf=open("/content/gdrive/My Drive/Colab Notebooks/Updated_Dataset_CSA/Dataset_V2_Labelled_Corrected.pickle","wb")
dump(final_list_2,nf)
nf.close()